{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc78331f",
   "metadata": {},
   "source": [
    "# NLP Project: Misinformation detection \n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"image/fake_news.jpeg\" alt=\"Exemple d'image\" style=\"width: 30%;\"/>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "### **Project Overview**\n",
    "\n",
    "This project is part of the **NLP course assessment**. The evaluation takes the form of a **personal project**, where the goal is to write a scientific mini-article reporting an experiment on an NLP problem. The approach is as follows:\n",
    "\n",
    "1. **Choice of an NLP problem**: Select a problem for which there are reference datasets and state-of-the-art results published in peer-reviewed conferences or journals.\n",
    "2. **Brief state-of-the-art**: Summarize the existing research and methods related to the problem.\n",
    "3. **Proposal and justification of an experiment**: Propose an experiment to evaluate a model and justify its relevance.\n",
    "4. **Data preparation**: Retrieve, format, and describe the data statistically.\n",
    "5. **Experiments**: Conduct experiments with the proposed model.\n",
    "6. **Analysis and conclusion**: Analyze the results and provide a conclusion.\n",
    "\n",
    "\n",
    "### **Group Members**\n",
    "\n",
    "- **`Amine Razig`**\n",
    "- **`Mohamed Keteb`**\n",
    "\n",
    "\n",
    "### **Objective**\n",
    "\n",
    "The objective of this project is to explore an NLP problem in depth, implement various methods, and analyze the results to draw meaningful conclusions. This will involve both classical NLP techniques and modern deep learning approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1e348c",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de2608fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c918d41",
   "metadata": {},
   "source": [
    "# Présenation du projet  : \n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"image/illustration2.png\" alt=\"Exemple d'image\" style=\"width: 50%;\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "### **Plan des explorations :**\n",
    "\n",
    "### Étape 1 : Analyse exploratoire des données (EDA)\n",
    "\n",
    "    **Objectif** : Comprendre la structure des données, détecter les valeurs manquantes, visualiser la distribution des classes, et explorer les caractéristiques textuelles.\n",
    "\n",
    "\n",
    "### Étape 2 : Prétraitement des données\n",
    "\n",
    "    **Objectif** : Nettoyer les données textuelles pour les rendre exploitables par des modèles NLP.\n",
    "\n",
    "### Étape 3 : Représentation des textes\n",
    "\n",
    "**Objectif** : Transformer les textes en une représentation numérique.\n",
    "\n",
    "    **Méthodes à tester** :\n",
    "    - Bag of Words (BoW).\n",
    "    - TF-IDF.\n",
    "    - Word embeddings (Word2Vec, GloVe, FastText).\n",
    "    - Sentence embeddings (BERT, RoBERTa).\n",
    "\n",
    "\n",
    "### Étape 4 : Modélisation classique\n",
    "\n",
    "**Objectif** : Utiliser des modèles de machine learning classiques pour classifier les textes.\n",
    "\n",
    "    **Modèles à tester** :\n",
    "    - Logistic Regression.\n",
    "    - Naive Bayes.\n",
    "    - Support Vector Machines (SVM).\n",
    "    - Random Forest.\n",
    "\n",
    "\n",
    "### Étape 5 : Modélisation avancée (Deep Learning)\n",
    "\n",
    "**Objectif** : Utiliser des modèles de deep learning pour améliorer les performances.\n",
    "\n",
    "    **Modèles à tester** :\n",
    "    - RNN (LSTM, GRU).\n",
    "    - CNN pour le texte.\n",
    "    - Transformers (BERT, DistilBERT, etc.).\n",
    "\n",
    "\n",
    "### Étape 6 : Évaluation des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c732e7",
   "metadata": {},
   "source": [
    "## Étape 1 : Analyse exploratoire des données (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7c5dca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake news dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23481 entries, 0 to 23480\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    23481 non-null  object\n",
      " 1   text     23481 non-null  object\n",
      " 2   subject  23481 non-null  object\n",
      " 3   date     23481 non-null  object\n",
      " 4   label    23481 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 917.4+ KB\n",
      "None\n",
      "\n",
      "True news dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21417 entries, 0 to 21416\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    21417 non-null  object\n",
      " 1   text     21417 non-null  object\n",
      " 2   subject  21417 non-null  object\n",
      " 3   date     21417 non-null  object\n",
      " 4   label    21417 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 836.7+ KB\n",
      "None\n",
      "\n",
      "Combined dataset:\n",
      "label\n",
      "fake    23481\n",
      "true    21417\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAHWCAYAAACVEZinAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAANd5JREFUeJzt3XtcFXX+x/H3AePgDfAGSCLgJRVvmKayK2pJoqKuaY/SrJQ0q9XNS7lqW2raZlnmpZtrbmqWu5aV1zJZb3hBUwwtS8vUtBQoTRAtUJjfHz2Yn0fwgiIHvryej8d5PDzf+czMZ4Zz4O2cmTkOy7IsAQAAGMbD3Q0AAADcCIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwYZ+LEiXI4HMWyro4dO6pjx4728w0bNsjhcGjJkiXFsv6BAwcqNDS0WNZ1rTIzMzV48GAFBgbK4XBoxIgRN3ydoaGh6t69+w1fT3EoDT9joKQi5KBEmz9/vhwOh/3w9vZWUFCQYmJiNGvWLJ0+fbpI1nPs2DFNnDhRycnJRbK8olSSe7sazz//vObPn6/HHntMCxcu1AMPPHDJ2tDQUJef94WP33//vRi7Lj0ufo9c6uHuoHT48GG7lw8//DDf9Lz/nPzyyy9u6A6mKufuBoCrMWnSJIWFhencuXNKSUnRhg0bNGLECL3yyitavny5mjVrZtc+/fTTGjt2bKGWf+zYMT377LMKDQ1VRETEVc+3Zs2aQq3nWlyut7feeku5ubk3vIfrsW7dOrVt21YTJky4qvqIiAg98cQT+ca9vLyKujUjtG/fXgsXLnQZGzx4sFq3bq0hQ4bYY5UqVSru1i5p0qRJ6t27d7EdcUXZRchBqdC1a1e1atXKfj5u3DitW7dO3bt3V8+ePfXNN9+ofPnykqRy5cqpXLkb+9I+e/asKlSo4PY/vDfddJNb13810tLSFB4eftX1N998s+6///4b2JFZ6tSpozp16riMPfroo6pTp85l9+P58+eVm5tb7K/hiIgIJScn6+OPP1bv3r2Ldd0oe/i4CqXWHXfcoWeeeUY//PCD3n33XXu8oHNy4uPj1a5dO/n5+alSpUpq0KCBnnrqKUl/nEdz2223SZLi4uLsQ+rz58+X9Md5N02aNFFSUpLat2+vChUq2PNefE5OnpycHD311FMKDAxUxYoV1bNnTx09etSlJjQ0VAMHDsw374XLvFJvBZ2vcebMGT3xxBMKDg6W0+lUgwYN9PLLL8uyLJc6h8OhYcOGaenSpWrSpImcTqcaN26s1atXF7zDL5KWlqZBgwYpICBA3t7eat68uRYsWGBPzzs/6dChQ1q1apXd++HDh69q+QWZN2+e7rjjDvn7+8vpdCo8PFxvvvnmVc27YMEClStXTqNHj7bHtm/fri5dusjX11cVKlRQhw4dtGXLlisuKzs7W+PHj1fLli3l6+urihUrKioqSuvXr3epy/uI5uWXX9acOXNUt25dOZ1O3XbbbdqxY0e+5eb9LLy9vdWkSRN9/PHHV7VtV3JhHzNmzLD7+Prrr+2Puy7+ueT9/DZs2OAyfq37LE/fvn11yy23aNKkSflekwW50vr27Nkjh8Oh5cuX22NJSUlyOBy69dZbXZbVtWtXtWnTxn6+c+dOxcTEqHr16ipfvrzCwsL00EMPXfW2oOTjSA5KtQceeEBPPfWU1qxZo4cffrjAmr1796p79+5q1qyZJk2aJKfTqQMHDti/KBs1aqRJkyZp/PjxGjJkiKKioiRJf/rTn+xlnDhxQl27dlXfvn11//33KyAg4LJ9/fOf/5TD4dCYMWOUlpamGTNmKDo6WsnJyfYRp6txNb1dyLIs9ezZU+vXr9egQYMUERGhzz77TKNHj9ZPP/2k6dOnu9Rv3rxZH330kf7617+qcuXKmjVrlvr06aMjR46oWrVql+zrt99+U8eOHXXgwAENGzZMYWFh+uCDDzRw4ECdOnVKw4cPV6NGjbRw4UKNHDlStWrVsj+CqlGjxmW3+dy5c/nOy6hQoYIqVKigN998U40bN1bPnj1Vrlw5rVixQn/961+Vm5uroUOHXnKZc+bM0aOPPqqnnnpKzz33nKQ/Pkbr2rWrWrZsqQkTJsjDw8MOUZs2bVLr1q0vubyMjAzNnTtX/fr108MPP6zTp0/r3//+t2JiYvT555/n+1hx0aJFOn36tB555BE5HA5NnTpVvXv31sGDB+2jcWvWrFGfPn0UHh6uKVOm6MSJE4qLi1OtWrUuu78KY968efr99981ZMgQOZ1OVa1atVDzX88+y+Pp6amnn35aDz744BWP5lzN+po0aSI/Pz8lJCSoZ8+ekqRNmzbJw8NDu3fvVkZGhnx8fJSbm6utW7faH+GlpaWpc+fOqlGjhsaOHSs/Pz8dPnxYH330UaH2CUo4CyjB5s2bZ0myduzYcckaX19fq0WLFvbzCRMmWBe+tKdPn25Jsn7++edLLmPHjh2WJGvevHn5pnXo0MGSZM2ePbvAaR06dLCfr1+/3pJk3XzzzVZGRoY9/v7771uSrJkzZ9pjISEh1oABA664zMv1NmDAACskJMR+vnTpUkuS9dxzz7nU3X333ZbD4bAOHDhgj0myvLy8XMZ2795tSbJeffXVfOu60IwZMyxJ1rvvvmuPZWdnW5GRkValSpVctj0kJMSKjY297PIurJWU7zFhwgTLsizr7Nmz+eaJiYmx6tSpk285eeucOXOm5XA4rMmTJ9vTc3Nzrfr161sxMTFWbm6uPX727FkrLCzMuvPOOy/b5/nz562srCyXsV9//dUKCAiwHnroIXvs0KFDliSrWrVq1smTJ+3xZcuWWZKsFStW2GMRERFWzZo1rVOnTtlja9assSS5/IyvRsWKFV1eW3l9+Pj4WGlpaS61ee+xQ4cOuYznvZbXr19vWdb177O8Hl566SXr/PnzVv369a3mzZvby8p73+a9TwuzvtjYWKt169b28969e1u9e/e2PD09rU8//dSyLMvatWuXJclatmyZZVmW9fHHH1/xdwtKPz6uQqlXqVKly15l5efnJ0latmzZNZ+k63Q6FRcXd9X1Dz74oCpXrmw/v/vuu1WzZk198skn17T+q/XJJ5/I09NTjz/+uMv4E088Icuy9Omnn7qMR0dHq27duvbzZs2aycfHRwcPHrziegIDA9WvXz977KabbtLjjz+uzMxMbdy48Zq3oU2bNoqPj3d5PPjgg5LkchQsPT1dv/zyizp06KCDBw8qPT0937KmTp2q4cOH68UXX9TTTz9tjycnJ+u7777TfffdpxMnTuiXX37RL7/8ojNnzqhTp05KSEi47GvF09PTPpclNzdXJ0+e1Pnz59WqVSvt2rUrX/29996rKlWq2M/zjsjl7efjx48rOTlZAwYMkK+vr1135513Fup8pivp06fPFY+kXcr17rML5R3N2b17t5YuXXrd64uKitKuXbt05swZSX8coezWrZsiIiK0adMmSX8c3XE4HGrXrp2k//+9sHLlSp07d+6a9glKPj6uQqmXmZkpf3//S06/9957NXfuXA0ePFhjx45Vp06d1Lt3b919993y8Li6nH/zzTcX6gTN+vXruzx3OByqV6/edZ2PcjV++OEHBQUFuQQs6Y+PvfKmX6h27dr5llGlShX9+uuvV1xP/fr18+2/S62nMKpXr67o6OgCp23ZskUTJkxQYmKizp496zItPT3dJSBs3LhRq1at0pgxY1zOw5Gk7777TpI0YMCAS/aRnp7uEkwutmDBAk2bNk379u1z+SMZFhaWr/bi/Zy33Lz9nLe/Ln7dSFKDBg0KDE7XoqDerlZR7LML9e/fX5MnT9akSZPUq1ev61pfVFSUzp8/r8TERAUHBystLU1RUVHau3evS8gJDw+3P6Lr0KGD+vTpo2effVbTp09Xx44d1atXL913331yOp1XtQ0o+Qg5KNV+/PFHpaenq169epesKV++vBISErR+/XqtWrVKq1ev1uLFi3XHHXdozZo18vT0vOJ6CnMezdW61OWzOTk5V9VTUbjUeqyrOCG0uH3//ffq1KmTGjZsqFdeeUXBwcHy8vLSJ598ounTp+c7itC4cWOdOnVKCxcu1COPPOLyBz6v9qWXXrrkLQMud8n1u+++q4EDB6pXr14aPXq0/P395enpqSlTpuj777/PV19S9nNBr+PLvQ4vdL377GJ5R3MGDhyoZcuW5ZtemPW1atVK3t7eSkhIUO3ateXv769bbrlFUVFReuONN5SVlaVNmzbprrvusufNu2nntm3btGLFCn322Wd66KGHNG3aNG3btq1EXXKPa0fIQamWd3+QmJiYy9Z5eHioU6dO6tSpk1555RU9//zz+sc//qH169crOjq6yO/Xkfe/0DyWZenAgQMu9/OpUqWKTp06lW/eH374weWS4ML0FhISov/97386ffq0y9Gcffv22dOLQkhIiPbs2aPc3FyXozlFvZ4LrVixQllZWVq+fLnLkZGLr2jKU716dS1ZskTt2rVTp06dtHnzZgUFBUmS/RGdj4/PJY8aXc6SJUtUp04dffTRRy4/n6u9F9DF8vbXxa8bSdq/f/81LfNq5R15ufi1ePHRuOvdZwW5//779dxzz+nZZ5+1Txq+lvV5eXmpdevW2rRpk2rXrm1/HBgVFaWsrCy99957Sk1NVfv27fPN27ZtW7Vt21b//Oc/tWjRIvXv31///e9/NXjw4CLZRrgX5+Sg1Fq3bp0mT56ssLAw9e/f/5J1J0+ezDeW9z/DrKwsSVLFihUl5f9Ff63eeecdl/OElixZouPHj6tr1672WN26dbVt2zZlZ2fbYytXrsx3qXlheuvWrZtycnL02muvuYxPnz5dDofDZf3Xo1u3bkpJSdHixYvtsfPnz+vVV19VpUqV1KFDhyJZz4XyjoZcePQjPT1d8+bNu+Q8tWrV0v/+9z/99ttvuvPOO3XixAlJUsuWLVW3bl29/PLLyszMzDffzz//XOhetm/frsTExKvfoAvUrFlTERERWrBggcu5RfHx8fr666+vaZlXKy9MJCQk2GM5OTmaM2eOS9317rOC5B3NSU5OdrkE/FrWFxUVpe3bt2v9+vV2yKlevboaNWqkF1980a7J8+uvv+Y7knbx7wWUfhzJQanw6aefat++fTp//rxSU1O1bt06xcfHKyQkRMuXL5e3t/cl5500aZISEhIUGxurkJAQpaWl6Y033lCtWrXskxDr1q0rPz8/zZ49W5UrV1bFihXVpk2baz6HoWrVqmrXrp3i4uKUmpqqGTNmqF69ei6XuQ8ePFhLlixRly5ddM899+j777/Xu+++63IicGF769Gjh26//Xb94x//0OHDh9W8eXOtWbNGy5Yt04gRI/It+1oNGTJE//rXvzRw4EAlJSUpNDRUS5Ys0ZYtWzRjxox85wQVhc6dO8vLy0s9evTQI488oszMTL311lvy9/fX8ePHLzlfvXr1tGbNGnXs2FExMTFat26dfHx8NHfuXHXt2lWNGzdWXFycbr75Zv30009av369fHx8tGLFiksus3v37vroo4901113KTY2VocOHdLs2bMVHh5e4B/kqzFlyhTFxsaqXbt2euihh3Ty5Em9+uqraty48TUv82o0btxYbdu21bhx43Ty5ElVrVpV//3vf3X+/HmXOg8Pj+vaZ5eSd27OxV9bUtj1RUVF6Z///KeOHj3qEmbat2+vf/3rXwoNDXW5HH/BggV64403dNddd6lu3bo6ffq03nrrLfn4+Khbt26F3g6UUG68sgu4orzLW/MeXl5eVmBgoHXnnXdaM2fOdLlUOc/Fl5CvXbvW+stf/mIFBQVZXl5eVlBQkNWvXz/r22+/dZlv2bJlVnh4uFWuXDmXS7Y7dOhgNW7cuMD+LnUJ+X/+8x9r3Lhxlr+/v1W+fHkrNjbW+uGHH/LNP23aNOvmm2+2nE6n9ec//9nauXNnvmVerreLLyG3LMs6ffq0NXLkSCsoKMi66aabrPr161svvfSSy2W4lvXHJeRDhw7N19OlLm2/WGpqqhUXF2dVr17d8vLyspo2bVrgZe6FvYT8crXLly+3mjVrZnl7e1uhoaHWiy++aL399tv5LoEuaDnbt2+3KleubLVv396+FP2LL76wevfubVWrVs1yOp1WSEiIdc8991hr1669bJ+5ubnW888/b4WEhFhOp9Nq0aKFtXLlynw/jwsvm76YLrg0Ps+HH35oNWrUyHI6nVZ4eLj10UcfFfgzvpJLXUJeUB+WZVnff/+9FR0dbTmdTisgIMB66qmnrPj4eJdLyPNc6z67XA8Xvs8vvtXD1a4vIyPD8vT0tCpXrmydP3/eHn/33XctSdYDDzzgUr9r1y6rX79+Vu3atS2n02n5+/tb3bt3t3bu3HnZ7UDp4rCsEniGIQAAwHXinBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYq0/fJyc3N1bFjx1S5cuUiv+MtAAC4MSzL0unTpxUUFHTZ7yAs0yHn2LFjCg4OdncbAADgGhw9etTlJo8XK9MhJ++urEePHpWPj4+buwEAAFcjIyNDwcHBV7y7epkOOXkfUfn4+BByAAAoZa50qgknHgMAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMVM7dDcA9QseucncLKEaHX4h1dwsAUOw4kgMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYKRy7m4AAFC0QseucncLKEaHX4h1dwslFkdyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEKFXKmTJmi2267TZUrV5a/v7969eql/fv3u9T8/vvvGjp0qKpVq6ZKlSqpT58+Sk1Ndak5cuSIYmNjVaFCBfn7+2v06NE6f/68S82GDRt06623yul0ql69epo/f36+fl5//XWFhobK29tbbdq00eeff16YzQEAAAYrVMjZuHGjhg4dqm3btik+Pl7nzp1T586ddebMGbtm5MiRWrFihT744ANt3LhRx44dU+/eve3pOTk5io2NVXZ2trZu3aoFCxZo/vz5Gj9+vF1z6NAhxcbG6vbbb1dycrJGjBihwYMH67PPPrNrFi9erFGjRmnChAnatWuXmjdvrpiYGKWlpV3P/gAAAIZwWJZlXevMP//8s/z9/bVx40a1b99e6enpqlGjhhYtWqS7775bkrRv3z41atRIiYmJatu2rT799FN1795dx44dU0BAgCRp9uzZGjNmjH7++Wd5eXlpzJgxWrVqlb766it7XX379tWpU6e0evVqSVKbNm1022236bXXXpMk5ebmKjg4WH/72980duzYAvvNyspSVlaW/TwjI0PBwcFKT0+Xj4/Pte6GUil07Cp3t4BidPiFWHe3gGLE+7tsKYvv74yMDPn6+l7x7/d1nZOTnp4uSapataokKSkpSefOnVN0dLRd07BhQ9WuXVuJiYmSpMTERDVt2tQOOJIUExOjjIwM7d271665cBl5NXnLyM7OVlJSkkuNh4eHoqOj7ZqCTJkyRb6+vvYjODj4ejYfAACUYNcccnJzczVixAj9+c9/VpMmTSRJKSkp8vLykp+fn0ttQECAUlJS7JoLA07e9Lxpl6vJyMjQb7/9pl9++UU5OTkF1uQtoyDjxo1Tenq6/Th69GjhNxwAAJQK5a51xqFDh+qrr77S5s2bi7KfG8rpdMrpdLq7DQAAUAyu6UjOsGHDtHLlSq1fv161atWyxwMDA5Wdna1Tp0651KempiowMNCuufhqq7znV6rx8fFR+fLlVb16dXl6ehZYk7cMAABQthUq5FiWpWHDhunjjz/WunXrFBYW5jK9ZcuWuummm7R27Vp7bP/+/Tpy5IgiIyMlSZGRkfryyy9droKKj4+Xj4+PwsPD7ZoLl5FXk7cMLy8vtWzZ0qUmNzdXa9eutWsAAEDZVqiPq4YOHapFixZp2bJlqly5sn3+i6+vr8qXLy9fX18NGjRIo0aNUtWqVeXj46O//e1vioyMVNu2bSVJnTt3Vnh4uB544AFNnTpVKSkpevrppzV06FD7o6RHH31Ur732mv7+97/roYce0rp16/T+++9r1ar/v2Jg1KhRGjBggFq1aqXWrVtrxowZOnPmjOLi4opq3wAAgFKsUCHnzTfflCR17NjRZXzevHkaOHCgJGn69Ony8PBQnz59lJWVpZiYGL3xxht2raenp1auXKnHHntMkZGRqlixogYMGKBJkybZNWFhYVq1apVGjhypmTNnqlatWpo7d65iYmLsmnvvvVc///yzxo8fr5SUFEVERGj16tX5TkYGAABl03XdJ6e0u9rr7E3EfTTKlrJ4H42yjPd32VIW39/Fcp8cAACAkoqQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADBSoUNOQkKCevTooaCgIDkcDi1dutRl+sCBA+VwOFweXbp0cak5efKk+vfvLx8fH/n5+WnQoEHKzMx0qdmzZ4+ioqLk7e2t4OBgTZ06NV8vH3zwgRo2bChvb281bdpUn3zySWE3BwAAGKrQIefMmTNq3ry5Xn/99UvWdOnSRcePH7cf//nPf1ym9+/fX3v37lV8fLxWrlyphIQEDRkyxJ6ekZGhzp07KyQkRElJSXrppZc0ceJEzZkzx67ZunWr+vXrp0GDBumLL75Qr1691KtXL3311VeF3SQAAGCgcoWdoWvXruratetla5xOpwIDAwuc9s0332j16tXasWOHWrVqJUl69dVX1a1bN7388ssKCgrSe++9p+zsbL399tvy8vJS48aNlZycrFdeecUOQzNnzlSXLl00evRoSdLkyZMVHx+v1157TbNnzy5w3VlZWcrKyrKfZ2RkFHbzAQBAKXFDzsnZsGGD/P391aBBAz322GM6ceKEPS0xMVF+fn52wJGk6OhoeXh4aPv27XZN+/bt5eXlZdfExMRo//79+vXXX+2a6Ohol/XGxMQoMTHxkn1NmTJFvr6+9iM4OLhIthcAAJQ8RR5yunTponfeeUdr167Viy++qI0bN6pr167KycmRJKWkpMjf399lnnLlyqlq1apKSUmxawICAlxq8p5fqSZvekHGjRun9PR0+3H06NHr21gAAFBiFfrjqivp27ev/e+mTZuqWbNmqlu3rjZs2KBOnToV9eoKxel0yul0urUHAABQPG74JeR16tRR9erVdeDAAUlSYGCg0tLSXGrOnz+vkydP2ufxBAYGKjU11aUm7/mVai51LhAAAChbbnjI+fHHH3XixAnVrFlTkhQZGalTp04pKSnJrlm3bp1yc3PVpk0buyYhIUHnzp2za+Lj49WgQQNVqVLFrlm7dq3LuuLj4xUZGXmjNwkAAJQChQ45mZmZSk5OVnJysiTp0KFDSk5O1pEjR5SZmanRo0dr27ZtOnz4sNauXau//OUvqlevnmJiYiRJjRo1UpcuXfTwww/r888/15YtWzRs2DD17dtXQUFBkqT77rtPXl5eGjRokPbu3avFixdr5syZGjVqlN3H8OHDtXr1ak2bNk379u3TxIkTtXPnTg0bNqwIdgsAACjtCh1ydu7cqRYtWqhFixaSpFGjRqlFixYaP368PD09tWfPHvXs2VO33HKLBg0apJYtW2rTpk0u58K89957atiwoTp16qRu3bqpXbt2LvfA8fX11Zo1a3To0CG1bNlSTzzxhMaPH+9yL50//elPWrRokebMmaPmzZtryZIlWrp0qZo0aXI9+wMAABjCYVmW5e4m3CUjI0O+vr5KT0+Xj4+Pu9spVqFjV7m7BRSjwy/EursFFCPe32VLWXx/X+3fb767CgAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADBSoUNOQkKCevTooaCgIDkcDi1dutRlumVZGj9+vGrWrKny5csrOjpa3333nUvNyZMn1b9/f/n4+MjPz0+DBg1SZmamS82ePXsUFRUlb29vBQcHa+rUqfl6+eCDD9SwYUN5e3uradOm+uSTTwq7OQAAwFCFDjlnzpxR8+bN9frrrxc4ferUqZo1a5Zmz56t7du3q2LFioqJidHvv/9u1/Tv31979+5VfHy8Vq5cqYSEBA0ZMsSenpGRoc6dOyskJERJSUl66aWXNHHiRM2ZM8eu2bp1q/r166dBgwbpiy++UK9evdSrVy999dVXhd0kAABgIIdlWdY1z+xw6OOPP1avXr0k/XEUJygoSE888YSefPJJSVJ6eroCAgI0f/589e3bV998843Cw8O1Y8cOtWrVSpK0evVqdevWTT/++KOCgoL05ptv6h//+IdSUlLk5eUlSRo7dqyWLl2qffv2SZLuvfdenTlzRitXrrT7adu2rSIiIjR79uwC+83KylJWVpb9PCMjQ8HBwUpPT5ePj8+17oZSKXTsKne3gGJ0+IVYd7eAYsT7u2wpi+/vjIwM+fr6XvHvd5Gek3Po0CGlpKQoOjraHvP19VWbNm2UmJgoSUpMTJSfn58dcCQpOjpaHh4e2r59u13Tvn17O+BIUkxMjPbv369ff/3VrrlwPXk1eespyJQpU+Tr62s/goODr3+jAQBAiVSkISclJUWSFBAQ4DIeEBBgT0tJSZG/v7/L9HLlyqlq1aouNQUt48J1XKomb3pBxo0bp/T0dPtx9OjRwm4iAAAoJcq5u4Hi5HQ65XQ63d0GAAAoBkV6JCcwMFCSlJqa6jKemppqTwsMDFRaWprL9PPnz+vkyZMuNQUt48J1XKombzoAACjbijTkhIWFKTAwUGvXrrXHMjIytH37dkVGRkqSIiMjderUKSUlJdk169atU25urtq0aWPXJCQk6Ny5c3ZNfHy8GjRooCpVqtg1F64nryZvPQAAoGwrdMjJzMxUcnKykpOTJf1xsnFycrKOHDkih8OhESNG6LnnntPy5cv15Zdf6sEHH1RQUJB9BVajRo3UpUsXPfzww/r888+1ZcsWDRs2TH379lVQUJAk6b777pOXl5cGDRqkvXv3avHixZo5c6ZGjRpl9zF8+HCtXr1a06ZN0759+zRx4kTt3LlTw4YNu/69AgAASr1Cn5Ozc+dO3X777fbzvOAxYMAAzZ8/X3//+9915swZDRkyRKdOnVK7du20evVqeXt72/O89957GjZsmDp16iQPDw/16dNHs2bNsqf7+vpqzZo1Gjp0qFq2bKnq1atr/PjxLvfS+dOf/qRFixbp6aef1lNPPaX69etr6dKlatKkyTXtCAAAYJbruk9OaXe119mbiPtolC1l8T4aZRnv77KlLL6/3XKfHAAAgJKCkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgpCIPORMnTpTD4XB5NGzY0J7++++/a+jQoapWrZoqVaqkPn36KDU11WUZR44cUWxsrCpUqCB/f3+NHj1a58+fd6nZsGGDbr31VjmdTtWrV0/z588v6k0BAACl2A05ktO4cWMdP37cfmzevNmeNnLkSK1YsUIffPCBNm7cqGPHjql379729JycHMXGxio7O1tbt27VggULNH/+fI0fP96uOXTokGJjY3X77bcrOTlZI0aM0ODBg/XZZ5/diM0BAAClULkbstBy5RQYGJhvPD09Xf/+97+1aNEi3XHHHZKkefPmqVGjRtq2bZvatm2rNWvW6Ouvv9b//vc/BQQEKCIiQpMnT9aYMWM0ceJEeXl5afbs2QoLC9O0adMkSY0aNdLmzZs1ffp0xcTE3IhNAgAApcwNOZLz3XffKSgoSHXq1FH//v115MgRSVJSUpLOnTun6Ohou7Zhw4aqXbu2EhMTJUmJiYlq2rSpAgIC7JqYmBhlZGRo7969ds2Fy8iryVvGpWRlZSkjI8PlAQAAzFTkIadNmzaaP3++Vq9erTfffFOHDh1SVFSUTp8+rZSUFHl5ecnPz89lnoCAAKWkpEiSUlJSXAJO3vS8aZerycjI0G+//XbJ3qZMmSJfX1/7ERwcfL2bCwAASqgi/7iqa9eu9r+bNWumNm3aKCQkRO+//77Kly9f1KsrlHHjxmnUqFH284yMDIIOAACGuuGXkPv5+emWW27RgQMHFBgYqOzsbJ06dcqlJjU11T6HJzAwMN/VVnnPr1Tj4+Nz2SDldDrl4+Pj8gAAAGa64SEnMzNT33//vWrWrKmWLVvqpptu0tq1a+3p+/fv15EjRxQZGSlJioyM1Jdffqm0tDS7Jj4+Xj4+PgoPD7drLlxGXk3eMgAAAIo85Dz55JPauHGjDh8+rK1bt+quu+6Sp6en+vXrJ19fXw0aNEijRo3S+vXrlZSUpLi4OEVGRqpt27aSpM6dOys8PFwPPPCAdu/erc8++0xPP/20hg4dKqfTKUl69NFHdfDgQf3973/Xvn379MYbb+j999/XyJEji3pzAABAKVXk5+T8+OOP6tevn06cOKEaNWqoXbt22rZtm2rUqCFJmj59ujw8PNSnTx9lZWUpJiZGb7zxhj2/p6enVq5cqccee0yRkZGqWLGiBgwYoEmTJtk1YWFhWrVqlUaOHKmZM2eqVq1amjt3LpePAwAAm8OyLMvdTbhLRkaGfH19lZ6eXubOzwkdu8rdLaAYHX4h1t0toBjx/i5byuL7+2r/fvPdVQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRSn3Ief311xUaGipvb2+1adNGn3/+ubtbAgAAJUCpDjmLFy/WqFGjNGHCBO3atUvNmzdXTEyM0tLS3N0aAABws1Idcl555RU9/PDDiouLU3h4uGbPnq0KFSro7bffdndrAADAzcq5u4FrlZ2draSkJI0bN84e8/DwUHR0tBITEwucJysrS1lZWfbz9PR0SVJGRsaNbbYEys066+4WUIzK4mu8LOP9XbaUxfd33jZblnXZulIbcn755Rfl5OQoICDAZTwgIED79u0rcJ4pU6bo2WefzTceHBx8Q3oESgrfGe7uAMCNUpbf36dPn5avr+8lp5fakHMtxo0bp1GjRtnPc3NzdfLkSVWrVk0Oh8ONnaE4ZGRkKDg4WEePHpWPj4+72wFQhHh/ly2WZen06dMKCgq6bF2pDTnVq1eXp6enUlNTXcZTU1MVGBhY4DxOp1NOp9NlzM/P70a1iBLKx8eHX4KAoXh/lx2XO4KTp9SeeOzl5aWWLVtq7dq19lhubq7Wrl2ryMhIN3YGAABKglJ7JEeSRo0apQEDBqhVq1Zq3bq1ZsyYoTNnziguLs7drQEAADcr1SHn3nvv1c8//6zx48crJSVFERERWr16db6TkQHpj48rJ0yYkO8jSwClH+9vFMRhXen6KwAAgFKo1J6TAwAAcDmEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIQZnw+++/u7sFAEAxI+TAWLm5uZo8ebJuvvlmVapUSQcPHpQkPfPMM/r3v//t5u4AXK9Nmzbp/vvvV2RkpH766SdJ0sKFC7V582Y3d4aSgpADYz333HOaP3++pk6dKi8vL3u8SZMmmjt3rhs7A3C9PvzwQ8XExKh8+fL64osvlJWVJUlKT0/X888/7+buUFIQcmCsd955R3PmzFH//v3l6elpjzdv3lz79u1zY2cArtdzzz2n2bNn66233tJNN91kj//5z3/Wrl273NgZShJCDoz1008/qV69evnGc3Nzde7cOTd0BKCo7N+/X+3bt8837uvrq1OnThV/QyiRCDkwVnh4uDZt2pRvfMmSJWrRooUbOgJQVAIDA3XgwIF845s3b1adOnXc0BFKolL9BZ3A5YwfP14DBgzQTz/9pNzcXH300Ufav3+/3nnnHa1cudLd7QG4Dg8//LCGDx+ut99+Ww6HQ8eOHVNiYqKefPJJPfPMM+5uDyUEX9AJo23atEmTJk3S7t27lZmZqVtvvVXjx49X586d3d0agOtgWZaef/55TZkyRWfPnpX0xzeRP/nkk5o8ebKbu0NJQciBsX788UfVqlWrwGnbtm1T27Zti7kjAEUtOztbBw4cUGZmpsLDw1WpUiV3t4QShJADY4WHh2vz5s2qWrWqy/iWLVsUGxvLyYkAYDjOyYGx2rZtq86dO2v9+vWqXLmyJCkhIUE9evTQxIkT3dscgOty++23y+FwXHL6unXrirEblFRcXQVjzZ07V7Vr11aPHj2UlZWl9evXKzY2VpMmTdLIkSPd3R6A6xAREaHmzZvbj/DwcGVnZ2vXrl1q2rSpu9tDCcHHVTBadna2YmNjdfbsWe3Zs0dTpkzRsGHD3N0WgBtk4sSJyszM1Msvv+zuVlACEHJglD179uQbO336tPr166fY2Fg99thj9nizZs2KszUAxeDAgQNq3bq1Tp486e5WUAIQcmAUDw8PORwOXfiyvvB53r8dDodycnLc1SaAG2ThwoUaM2aMjh075u5WUAJw4jGMcujQIXe3AKAY9O7d2+W5ZVk6fvy4du7cyc0AYeNIDgCg1ImLi3N57uHhoRo1auiOO+7gZp+wEXJgvK+//lpHjhxRdna2y3jPnj3d1BGA65GTk6MtW7aoadOmqlKlirvbQQlGyIGxDh48qLvuuktffvllvvNyJHFODlCKeXt765tvvlFYWJi7W0EJxn1yYKzhw4crLCxMaWlpqlChgvbu3auEhAS1atVKGzZscHd7AK5DkyZNdPDgQXe3gRKOIzkwVvXq1bVu3To1a9ZMvr6++vzzz9WgQQOtW7dOTzzxhL744gt3twjgGq1evVrjxo3T5MmT1bJlS1WsWNFluo+Pj5s6Q0nC1VUwVk5Ojv11DtWrV9exY8fUoEEDhYSEaP/+/W7uDsD16Natm6Q/zq278OsduEUELkTIgbGaNGmi3bt3KywsTG3atNHUqVPl5eWlOXPmqE6dOu5uD8B1mDdvnoKDg+Xp6ekynpubqyNHjripK5Q0fFwFo+zZs0dNmjSRh4eHPvvsM509e1Z33XWXDhw4oO7du+vbb79VtWrVtHjxYt1xxx3ubhfANfL09NTx48fl7+/vMn7ixAn5+/tzJAeSCDkwzIW/+OrUqaMdO3aoWrVq9vSTJ0+qSpUql/32YgAln4eHh1JTU1WjRg2X8R9++EHh4eE6c+aMmzpDScLHVTCKn5+fDh06JH9/fx0+fFi5ubku06tWreqmzgAUhVGjRkn641YQzzzzjCpUqGBPy8nJ0fbt2xUREeGm7lDSEHJglD59+qhDhw6qWbOmHA6HWrVqle8z+zxcfgqUPnlXRVqWpS+//FJeXl72NC8vLzVv3lxPPvmku9pDCcPHVTDO6tWrdeDAAT3++OOaNGmSfYXVxYYPH17MnQEoKnFxcZo5cyaXiuOyCDkwVlxcnGbNmnXJkAMAMBshBwAAGImvdQAAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAlVseOHTVixIirqt2wYYMcDodOnTp1XesMDQ3VjBkzrmsZAEoGQg4AADASIQcAABiJkAOgVFi4cKFatWqlypUrKzAwUPfdd5/S0tLy1W3ZskXNmjWTt7e32rZtq6+++spl+ubNmxUVFaXy5csrODhYjz/+OF/mCBiKkAOgVDh37pwmT56s3bt3a+nSpTp8+LAGDhyYr2706NGaNm2aduzYoRo1aqhHjx46d+6cJOn7779Xly5d1KdPH+3Zs0eLFy/W5s2bNWzYsGLeGgDFgS/oBFAqPPTQQ/a/69Spo1mzZum2225TZmamKlWqZE+bMGGC7rzzTknSggULVKtWLX388ce65557NGXKFPXv398+mbl+/fqaNWuWOnTooDfffFPe3t7Fuk0AbiyO5AAoFZKSktSjRw/Vrl1blStXVocOHSRJR44ccamLjIy0/121alU1aNBA33zzjSRp9+7dmj9/vipVqmQ/YmJilJubq0OHDhXfxgAoFhzJAVDinTlzRjExMYqJidF7772nGjVq6MiRI4qJiVF2dvZVLyczM1OPPPKIHn/88XzTateuXZQtAygBCDkASrx9+/bpxIkTeuGFFxQcHCxJ2rlzZ4G127ZtswPLr7/+qm+//VaNGjWSJN166636+uuvVa9eveJpHIBb8XEVgBKvdu3a8vLy0quvvqqDBw9q+fLlmjx5coG1kyZN0tq1a/XVV19p4MCBql69unr16iVJGjNmjLZu3aphw4YpOTlZ3333nZYtW8aJx4ChCDkASrwaNWpo/vz5+uCDDxQeHq4XXnhBL7/8coG1L7zwgoYPH66WLVsqJSVFK1askJeXlySpWbNm2rhxo7799ltFRUWpRYsWGj9+vIKCgopzcwAUE4dlWZa7mwAAAChqHMkBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJH+D7Qs0kC9i3OwAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.eda import load_and_explore_data\n",
    "\n",
    "data = load_and_explore_data('data/Fake.csv', 'data/True.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce9c2ad",
   "metadata": {},
   "source": [
    "### Statistiques descriptives sur les longueurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f92e2c",
   "metadata": {},
   "source": [
    "## Étape 2 : Prétraitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f58ac9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/onyxia/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple avant nettoyage :\n",
      "Donald Trump just couldn t wish all Americans a Happy New Year and leave it at that. Instead, he had to give a shout out to his enemies, haters and  the very dishonest fake news media.  The former reality show star had just one job to do and he couldn t do it. As our Country rapidly grows stronger and smarter, I want to wish all of my friends, supporters, enemies, haters, and even the very dishonest Fake News Media, a Happy and Healthy New Year,  President Angry Pants tweeted.  2018 will be a great year for America! As our Country rapidly grows stronger and smarter, I want to wish all of my friends, supporters, enemies, haters, and even the very dishonest Fake News Media, a Happy and Healthy New Year. 2018 will be a great year for America!  Donald J. Trump (@realDonaldTrump) December 31, 2017Trump s tweet went down about as welll as you d expect.What kind of president sends a New Year s greeting like this despicable, petty, infantile gibberish? Only Trump! His lack of decency won t even allow him to rise above the gutter long enough to wish the American citizens a happy new year!  Bishop Talbert Swan (@TalbertSwan) December 31, 2017no one likes you  Calvin (@calvinstowell) December 31, 2017Your impeachment would make 2018 a great year for America, but I ll also accept regaining control of Congress.  Miranda Yaver (@mirandayaver) December 31, 2017Do you hear yourself talk? When you have to include that many people that hate you you have to wonder? Why do the they all hate me?  Alan Sandoval (@AlanSandoval13) December 31, 2017Who uses the word Haters in a New Years wish??  Marlene (@marlene399) December 31, 2017You can t just say happy new year?  Koren pollitt (@Korencarpenter) December 31, 2017Here s Trump s New Year s Eve tweet from 2016.Happy New Year to all, including to my many enemies and those who have fought me and lost so badly they just don t know what to do. Love!  Donald J. Trump (@realDonaldTrump) December 31, 2016This is nothing new for Trump. He s been doing this for years.Trump has directed messages to his  enemies  and  haters  for New Year s, Easter, Thanksgiving, and the anniversary of 9/11. pic.twitter.com/4FPAe2KypA  Daniel Dale (@ddale8) December 31, 2017Trump s holiday tweets are clearly not presidential.How long did he work at Hallmark before becoming President?  Steven Goodine (@SGoodine) December 31, 2017He s always been like this . . . the only difference is that in the last few years, his filter has been breaking down.  Roy Schulze (@thbthttt) December 31, 2017Who, apart from a teenager uses the term haters?  Wendy (@WendyWhistles) December 31, 2017he s a fucking 5 year old  Who Knows (@rainyday80) December 31, 2017So, to all the people who voted for this a hole thinking he would change once he got into power, you were wrong! 70-year-old men don t change and now he s a year older.Photo by Andrew Burton/Getty Images.\n",
      "\n",
      "Exemple après nettoyage :\n",
      "donald trump wish american happy new year leave instead give shout enemy hater dishonest fake news medium former reality show star one job country rapidly grows stronger smarter want wish friend supporter enemy hater even dishonest fake news medium happy healthy new year president angry pant tweeted great year america country rapidly grows stronger smarter want wish friend supporter enemy hater even dishonest fake news medium happy healthy new year great year america donald j trump realdonaldtrump december trump tweet went welll expectwhat kind president sends new year greeting like despicable petty infantile gibberish trump lack decency even allow rise gutter long enough wish american citizen happy new year bishop talbert swan talbertswan december one like calvin calvinstowell december impeachment would make great year america also accept regaining control congress miranda yaver mirandayaver december hear talk include many people hate wonder hate alan sandoval alansandoval december us word hater new year wish marlene marlene december say happy new year koren pollitt korencarpenter december trump new year eve tweet happy new year including many enemy fought lost badly know love donald j trump realdonaldtrump december nothing new trump yearstrump directed message enemy hater new year easter thanksgiving anniversary pictwittercomfpaekypa daniel dale ddale december trump holiday tweet clearly presidentialhow long work hallmark becoming president steven goodine sgoodine december always like difference last year filter breaking roy schulze thbthttt december apart teenager us term hater wendy wendywhistles december fucking year old know rainyday december people voted hole thinking would change got power wrong yearold men change year olderphoto andrew burtongetty image\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Télécharger les ressources nécessaires de NLTK\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Initialiser les stopwords et le lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convertir en minuscules\n",
    "    text = text.lower()\n",
    "    # Supprimer les caractères spéciaux et les chiffres\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Supprimer les stopwords et appliquer la lemmatisation\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Appliquer le prétraitement sur les colonnes 'title' et 'text'\n",
    "data['cleaned_title'] = data['title'].apply(preprocess_text)\n",
    "data['cleaned_text'] = data['text'].apply(preprocess_text)\n",
    "\n",
    "# Afficher un exemple avant et après le nettoyage\n",
    "print(\"Exemple avant nettoyage :\")\n",
    "print(data['text'].iloc[0])\n",
    "print(\"\\nExemple après nettoyage :\")\n",
    "print(data['cleaned_text'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63dad39",
   "metadata": {},
   "source": [
    "## Étape 3 : Représentation des textes\n",
    "#### L'objectif est de transformer les textes en une représentation numérique. On test diffrentes approches : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01c7496",
   "metadata": {},
   "source": [
    "**Word Embeddings (Word2Vec, GloVe, FastText)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa81ab26",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy.char'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Word2Vec\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Tokeniser les textes nettoyés\u001b[39;00m\n\u001b[32m      4\u001b[39m tokenized_texts = data[\u001b[33m'\u001b[39m\u001b[33mcleaned_text\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x.split())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/gensim/__init__.py:11\u001b[39m\n\u001b[32m      7\u001b[39m __version__ = \u001b[33m'\u001b[39m\u001b[33m4.3.3\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[32m     14\u001b[39m logger = logging.getLogger(\u001b[33m'\u001b[39m\u001b[33mgensim\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logger.handlers:  \u001b[38;5;66;03m# To ensure reload() doesn't add another one\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/gensim/parsing/__init__.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"This package contains functions to preprocess raw text\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mporter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PorterStemmer  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[32m      5\u001b[39m     preprocess_documents,\n\u001b[32m      6\u001b[39m     preprocess_string,\n\u001b[32m      7\u001b[39m     read_file,\n\u001b[32m      8\u001b[39m     read_files,\n\u001b[32m      9\u001b[39m     remove_stopwords,\n\u001b[32m     10\u001b[39m     split_alphanum,\n\u001b[32m     11\u001b[39m     stem_text,\n\u001b[32m     12\u001b[39m     strip_multiple_whitespaces,\n\u001b[32m     13\u001b[39m     strip_non_alphanum,\n\u001b[32m     14\u001b[39m     strip_numeric,\n\u001b[32m     15\u001b[39m     strip_punctuation,\n\u001b[32m     16\u001b[39m     strip_short,\n\u001b[32m     17\u001b[39m     strip_tags,\n\u001b[32m     18\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/gensim/parsing/preprocessing.py:26\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstring\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mglob\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparsing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mporter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PorterStemmer\n\u001b[32m     30\u001b[39m STOPWORDS = \u001b[38;5;28mfrozenset\u001b[39m([\n\u001b[32m     31\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mall\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msix\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mjust\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mless\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbeing\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mindeed\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mover\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmove\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33manyway\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfour\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnot\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mown\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mthrough\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     32\u001b[39m     \u001b[33m'\u001b[39m\u001b[33musing\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfifty\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwhere\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmill\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33monly\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mfind\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbefore\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mone\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mwhose\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhow\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msomewhere\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     58\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmake\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33monce\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     59\u001b[39m ])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/gensim/utils.py:35\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtypes\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msmart_open\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28mopen\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m gensim_version\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/scipy/sparse/__init__.py:294\u001b[39m\n\u001b[32m    288\u001b[39m \u001b[38;5;66;03m# Original code by Travis Oliphant.\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[38;5;66;03m# Modified and extended by Ed Schofield, Robert Cimrman,\u001b[39;00m\n\u001b[32m    290\u001b[39m \u001b[38;5;66;03m# Nathan Bell, and Jake Vanderplas.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_warnings\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_csr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_csc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/scipy/sparse/_base.py:5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m warn\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_util\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VisibleDeprecationWarning\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sputils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (asmatrix, check_reshape_kwargs, check_shape,\n\u001b[32m      8\u001b[39m                        get_sum_dtype, isdense, isscalarlike,\n\u001b[32m      9\u001b[39m                        matrix, validateaxis,)\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_matrix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m spmatrix\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/scipy/_lib/_util.py:18\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     Optional,\n\u001b[32m     12\u001b[39m     Union,\n\u001b[32m     13\u001b[39m     TYPE_CHECKING,\n\u001b[32m     14\u001b[39m     TypeVar,\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_array_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array_namespace\n\u001b[32m     21\u001b[39m AxisError: \u001b[38;5;28mtype\u001b[39m[\u001b[38;5;167;01mException\u001b[39;00m]\n\u001b[32m     22\u001b[39m ComplexWarning: \u001b[38;5;28mtype\u001b[39m[\u001b[38;5;167;01mWarning\u001b[39;00m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/scipy/_lib/_array_api.py:17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array_api_compat\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marray_api_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     18\u001b[39m     is_array_api_obj,\n\u001b[32m     19\u001b[39m     size,\n\u001b[32m     20\u001b[39m     numpy \u001b[38;5;28;01mas\u001b[39;00m np_compat,\n\u001b[32m     21\u001b[39m )\n\u001b[32m     23\u001b[39m __all__ = [\u001b[33m'\u001b[39m\u001b[33marray_namespace\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m_asarray\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msize\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# To enable array API and strict array-like input validation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/scipy/_lib/array_api_compat/numpy/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# from numpy import * doesn't overwrite these builtin names\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28mabs\u001b[39m, \u001b[38;5;28mmax\u001b[39m, \u001b[38;5;28mmin\u001b[39m, \u001b[38;5;28mround\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/numpy/__init__.py:370\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr)\u001b[39m\n\u001b[32m    365\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m()\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m:\n\u001b[32m    367\u001b[39m     msg = (\u001b[33m\"\u001b[39m\u001b[33mThe current Numpy installation (\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[33m) fails to \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    368\u001b[39m            \u001b[33m\"\u001b[39m\u001b[33mpass simple sanity checks. This can be caused for example \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    369\u001b[39m            \u001b[33m\"\u001b[39m\u001b[33mby incorrect BLAS library being linked in, or by mixing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m            \u001b[33m\"\u001b[39m\u001b[33mpackage managers (pip, conda, apt, ...). Search closed \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    371\u001b[39m            \u001b[33m\"\u001b[39m\u001b[33mnumpy issues for similar problems.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    372\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg.format(\u001b[34m__file__\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy.char'"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Tokeniser les textes nettoyés\n",
    "tokenized_texts = data['cleaned_text'].apply(lambda x: x.split())\n",
    "\n",
    "# Entraîner un modèle Word2Vec\n",
    "word2vec_model = Word2Vec(sentences=tokenized_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Exemple : Obtenir le vecteur pour un mot\n",
    "print(\"Vecteur pour le mot 'news':\", word2vec_model.wv['news'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f845ef8f",
   "metadata": {},
   "source": [
    "## Étape 4 : Modélisation classique\n",
    "Objectif : Utiliser des modèles de machine learning classiques pour classifier les textes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9383064f-e7af-4de4-8da1-a9a3df58331f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenized_texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(word2vec_model.wv[doc], axis=\u001b[32m0\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 4. Calculer les vecteurs pour tous les textes\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m X_wv = np.array([document_vector(doc) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtokenized_texts\u001b[49m])\n",
      "\u001b[31mNameError\u001b[39m: name 'tokenized_texts' is not defined"
     ]
    }
   ],
   "source": [
    "# 3. Fonction pour obtenir un vecteur moyen pour chaque document\n",
    "def document_vector(doc):\n",
    "    doc = [word for word in doc if word in word2vec_model.wv]\n",
    "    if len(doc) == 0:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "    return np.mean(word2vec_model.wv[doc], axis=0)\n",
    "\n",
    "# 4. Calculer les vecteurs pour tous les textes\n",
    "X_wv = np.array([document_vector(doc) for doc in tokenized_texts])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77f8ce15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraînement : (35918, 5000)\n",
      "Taille de l'ensemble de test : (8980, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X = X_wv  # Utilisez TF-IDF ou une autre représentation\n",
    "y = data['label']   # La colonne des étiquettes ('fake' ou 'true')\n",
    "\n",
    "# Encodage des étiquettes en valeurs numériques\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Division des données\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Taille de l'ensemble d'entraînement :\", X_train.shape)\n",
    "print(\"Taille de l'ensemble de test :\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12d74eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.987305122494432\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4733\n",
      "           1       0.99      0.99      0.99      4247\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialiser et entraîner le modèle\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# Évaluation\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8102d34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.929064587973274\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      4733\n",
      "           1       0.93      0.92      0.92      4247\n",
      "\n",
      "    accuracy                           0.93      8980\n",
      "   macro avg       0.93      0.93      0.93      8980\n",
      "weighted avg       0.93      0.93      0.93      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Initialiser et entraîner le modèle\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred = nb_model.predict(X_test)\n",
    "\n",
    "# Évaluation\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81785532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9947661469933184\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      4733\n",
      "           1       0.99      1.00      0.99      4247\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Initialiser et entraîner le modèle\n",
    "svm_model = LinearSVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Évaluation\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7abcb6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9974387527839643\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4733\n",
      "           1       1.00      1.00      1.00      4247\n",
      "\n",
      "    accuracy                           1.00      8980\n",
      "   macro avg       1.00      1.00      1.00      8980\n",
      "weighted avg       1.00      1.00      1.00      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialiser et entraîner le modèle\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Évaluation\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac1429e-3f12-4b1e-bfd4-320300da7a47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
